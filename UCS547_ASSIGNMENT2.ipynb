{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name:Tushar  \n",
        "Roll no:102303206  \n",
        "Assignment2(UCS547)"
      ],
      "metadata": {
        "id": "YbgMo-1Nkpzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: Identify !, %, and %% used in cell in Google Colab."
      ],
      "metadata": {
        "id": "ANdRmnVXmeGo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz6Jkzq0kofk",
        "outputId": "5abd9e39-3480-4f86-96d7-9a704234caff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running with !\n",
            "CPU times: user 20.9 ms, sys: 0 ns, total: 20.9 ms\n",
            "Wall time: 21.4 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "499999500000"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!echo \"Running with !\"\n",
        "\n",
        "%time sum(range(1000000))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "echo \"Running with %%\"\n",
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNKjUoXtmykz",
        "outputId": "15576a56-8848-4ec1-8821-b28e80d23749"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running with %%\n",
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2: Identify all key nvidia-smi commands with multiple options"
      ],
      "metadata": {
        "id": "SaeVPO42m3GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "\n",
        "!nvidia-smi --query-gpu=name,temperature.gpu,utilization.gpu,memory.total,memory.used --format=csv,noheader,nounits\n",
        "\n",
        "!nvidia-smi --query-compute-apps=pid,used_memory --format=csv,noheader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiAc0yd5nDfG",
        "outputId": "7e5df6f8-63c6-495a-99a4-dae160f46273"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb 13 10:56:26 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Tesla T4, 51, 0, 15360, 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3: Debug common CUDA errors (zero output, incorrect indexing, PTX errors)"
      ],
      "metadata": {
        "id": "REktUIPwpS_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile debug_cuda.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 5;\n",
        "    int h_a[5] = {1,2,3,4,5};\n",
        "    int h_b[5] = {5,4,3,2,1};\n",
        "    int h_c[5];\n",
        "\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    cudaMalloc(&d_a, n*sizeof(int));\n",
        "    cudaMalloc(&d_b, n*sizeof(int));\n",
        "    cudaMalloc(&d_c, n*sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, n*sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, n*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    add<<<1,5>>>(d_a, d_b, d_c, n);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess)\n",
        "        printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "\n",
        "    cudaMemcpy(h_c, d_c, n*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for(int i=0;i<n;i++)\n",
        "        printf(\"%d \", h_c[i]);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgNlTocgpdL1",
        "outputId": "376e346e-0000-4f2d-ba61-1e70ae58594e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing debug_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc debug_cuda.cu -o debug_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwfH7vUkp23o",
        "outputId": "86aee5c9-c433-4876-f5a0-b7d5b47a9baf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : Support for offline compilation for architectures prior to '<compute/sm/lto>_75' will be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 debug_cuda.cu -o debug_cuda"
      ],
      "metadata": {
        "id": "BwaHJTARp8Sk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./debug_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oonnWjoqA3w",
        "outputId": "9c6a85a3-8e50-4808-f430-f5eb9d374005"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 6 6 6 6 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4: Write a CUDA C/C++ program to demonstrate GPU kernel execu'on and thread indexing.  \n",
        "\n",
        "a. Launch a CUDA kernel using: 1 block and 8 threads"
      ],
      "metadata": {
        "id": "b7xgmO_NqH1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kernel_index.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void printThreadInfo() {\n",
        "    int thread_id = threadIdx.x;\n",
        "    int block_id = blockIdx.x;\n",
        "    int global_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    printf(\"Block ID: %d | Thread ID: %d | Global ID: %d\\n\",\n",
        "            block_id, thread_id, global_id);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printThreadInfo<<<1, 8>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLBW6HnGqWKh",
        "outputId": "02feecef-9115-4f5d-c75e-eeb15d61f936"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing kernel_index.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -std=c++11 -Wno-deprecated-gpu-targets kernel_index.cu -o kernel_index"
      ],
      "metadata": {
        "id": "NbYeAV06qeV-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./kernel_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay1zCUWgqiIs",
        "outputId": "0e68cf8e-184f-4b43-d089-3c090730d019"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block ID: 0 | Thread ID: 0 | Global ID: 0\n",
            "Block ID: 0 | Thread ID: 1 | Global ID: 1\n",
            "Block ID: 0 | Thread ID: 2 | Global ID: 2\n",
            "Block ID: 0 | Thread ID: 3 | Global ID: 3\n",
            "Block ID: 0 | Thread ID: 4 | Global ID: 4\n",
            "Block ID: 0 | Thread ID: 5 | Global ID: 5\n",
            "Block ID: 0 | Thread ID: 6 | Global ID: 6\n",
            "Block ID: 0 | Thread ID: 7 | Global ID: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Each thread must print: Hello from GPU thread global_thread_id"
      ],
      "metadata": {
        "id": "Ehymx_RPqn-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello_gpu.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void helloKernel() {\n",
        "    int global_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    printf(\"Hello from GPU thread %d\\n\", global_id);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    helloKernel<<<1, 8>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mHihnMmq1R8",
        "outputId": "d07cf5b8-4c64-4263-f33b-59917e34bf7c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello_gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -std=c++11 -Wno-deprecated-gpu-targets hello_gpu.cu -o hello_gpu"
      ],
      "metadata": {
        "id": "Z9zAfWfOq54u"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXd5PBluq9ab",
        "outputId": "111c4d74-c463-4f90-98f3-7ac0677b4c61"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from GPU thread 0\n",
            "Hello from GPU thread 1\n",
            "Hello from GPU thread 2\n",
            "Hello from GPU thread 3\n",
            "Hello from GPU thread 4\n",
            "Hello from GPU thread 5\n",
            "Hello from GPU thread 6\n",
            "Hello from GPU thread 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Compute the global thread ID using: global_thread_id = blockIdx.x * blockDim.x +\n",
        "threadIdx.x"
      ],
      "metadata": {
        "id": "C-iOTt1-rCs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile global_id.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void computeGlobalID() {\n",
        "    int global_thread_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    printf(\"Block: %d | Thread: %d | Global Thread ID: %d\\n\",\n",
        "           blockIdx.x, threadIdx.x, global_thread_id);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    computeGlobalID<<<1, 8>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWYe6wgDrG91",
        "outputId": "ccd2735e-7b71-4469-b3b2-e4d3d010b04a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing global_id.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -Wno-deprecated-gpu-targets global_id.cu -o global_id"
      ],
      "metadata": {
        "id": "vG_lEDKWrL46"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./global_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC9e1-9wrQrL",
        "outputId": "b7aae15a-4a60-4e99-d53a-0b8287747daf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block: 0 | Thread: 0 | Global Thread ID: 0\n",
            "Block: 0 | Thread: 1 | Global Thread ID: 1\n",
            "Block: 0 | Thread: 2 | Global Thread ID: 2\n",
            "Block: 0 | Thread: 3 | Global Thread ID: 3\n",
            "Block: 0 | Thread: 4 | Global Thread ID: 4\n",
            "Block: 0 | Thread: 5 | Global Thread ID: 5\n",
            "Block: 0 | Thread: 6 | Global Thread ID: 6\n",
            "Block: 0 | Thread: 7 | Global Thread ID: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Clearly separate: Host code (CPU) & Device code (GPU kernel)"
      ],
      "metadata": {
        "id": "78xaaOMkrwne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile host_device_demo.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "/* =========================\n",
        "   Device Code (GPU Kernel)\n",
        "   ========================= */\n",
        "__global__ void helloKernel() {\n",
        "    int global_thread_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    printf(\"Hello from GPU thread %d\\n\", global_thread_id);\n",
        "}\n",
        "\n",
        "/* =========================\n",
        "   Host Code (CPU)\n",
        "   ========================= */\n",
        "int main() {\n",
        "\n",
        "    printf(\"Launching GPU Kernel...\\n\");\n",
        "\n",
        "    helloKernel<<<1, 8>>>();\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    printf(\"Kernel Execution Completed.\\n\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgTYEA8Grz8v",
        "outputId": "da25457d-4084-478b-eca5-61d6b41331ee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing host_device_demo.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -std=c++11 -Wno-deprecated-gpu-targets host_device_demo.cu -o host_device_demo"
      ],
      "metadata": {
        "id": "s-wJ3toSr7zz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./host_device_demo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDH5EV56r594",
        "outputId": "e6ee3d88-ae05-4624-8fa9-1c037b91e4fa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching GPU Kernel...\n",
            "Hello from GPU thread 0\n",
            "Hello from GPU thread 1\n",
            "Hello from GPU thread 2\n",
            "Hello from GPU thread 3\n",
            "Hello from GPU thread 4\n",
            "Hello from GPU thread 5\n",
            "Hello from GPU thread 6\n",
            "Hello from GPU thread 7\n",
            "Kernel Execution Completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5: Write a CUDA program to demonstrate host and device memory separation.  \n",
        "\n",
        "a. Create an integer array of size 5 on the host (CPU)."
      ],
      "metadata": {
        "id": "pMSPlhAAsArF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile memory_separation.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "/* =========================\n",
        "   Device Code (GPU Kernel)\n",
        "   ========================= */\n",
        "__global__ void printDeviceArray(int *d_arr) {\n",
        "    int i = threadIdx.x;\n",
        "    printf(\"Device Array[%d] = %d\\n\", i, d_arr[i]);\n",
        "}\n",
        "\n",
        "/* =========================\n",
        "   Host Code (CPU)\n",
        "   ========================= */\n",
        "int main() {\n",
        "\n",
        "    // Host memory (CPU)\n",
        "    int h_arr[5] = {10, 20, 30, 40, 50};\n",
        "\n",
        "    // Device memory (GPU)\n",
        "    int *d_arr;\n",
        "    cudaMalloc((void**)&d_arr, 5 * sizeof(int));\n",
        "\n",
        "    // Copy Host → Device\n",
        "    cudaMemcpy(d_arr, h_arr, 5 * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernel (1 block, 5 threads)\n",
        "    printDeviceArray<<<1, 5>>>(d_arr);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaFree(d_arr);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXEVv1zYsK_h",
        "outputId": "492cde89-4934-41d6-a8eb-2c2feac7ade9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing memory_separation.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -std=c++11 -Wno-deprecated-gpu-targets memory_separation.cu -o memory_separation"
      ],
      "metadata": {
        "id": "rygLBhTZsRDQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./memory_separation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEH8Y5PYsUBp",
        "outputId": "71c41e5c-6279-4a67-93f0-3f3dba5818c7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Array[0] = 10\n",
            "Device Array[1] = 20\n",
            "Device Array[2] = 30\n",
            "Device Array[3] = 40\n",
            "Device Array[4] = 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Allocate corresponding memory on the device (GPU) using cudaMalloc()."
      ],
      "metadata": {
        "id": "dtgy6mFgsXMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile memory_demo.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void modifyArray(int *d_arr) {\n",
        "    int i = threadIdx.x;\n",
        "    d_arr[i] = d_arr[i] * 2;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    int h_arr[5] = {1, 2, 3, 4, 5};\n",
        "    int *d_arr;\n",
        "\n",
        "    printf(\"Host Array Before GPU:\\n\");\n",
        "    for(int i = 0; i < 5; i++)\n",
        "        printf(\"%d \", h_arr[i]);\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    cudaMalloc((void**)&d_arr, 5 * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_arr, h_arr, 5 * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    modifyArray<<<1,5>>>(d_arr);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(h_arr, d_arr, 5 * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Host Array After GPU Modification:\\n\");\n",
        "    for(int i = 0; i < 5; i++)\n",
        "        printf(\"%d \", h_arr[i]);\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    cudaFree(d_arr);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nE_hvcWsalZ",
        "outputId": "8b3b490e-30a4-4483-cc64-06a49f8b7200"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing memory_demo.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -std=c++11 -Wno-deprecated-gpu-targets memory_demo.cu -o memory_demo"
      ],
      "metadata": {
        "id": "XvBnvNwBsf2I"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./memory_demo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBEqKVDTs85y",
        "outputId": "be930186-8348-4f0a-8e2e-927d4363576b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Host Array Before GPU:\n",
            "1 2 3 4 5 \n",
            "Host Array After GPU Modification:\n",
            "2 4 6 8 10 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Copy data from host to device using cudaMemcpy()."
      ],
      "metadata": {
        "id": "pAZpKsLVtjWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile memcpy_demo.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "int main() {\n",
        "\n",
        "    // Host memory (CPU)\n",
        "    int h_arr[5] = {10, 20, 30, 40, 50};\n",
        "\n",
        "    // Device memory pointer (GPU)\n",
        "    int *d_arr;\n",
        "\n",
        "    // Allocate memory on GPU\n",
        "    cudaMalloc((void**)&d_arr, 5 * sizeof(int));\n",
        "\n",
        "    // Copy data from Host to Device\n",
        "    cudaMemcpy(d_arr, h_arr, 5 * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    printf(\"Data copied from Host to Device successfully.\\n\");\n",
        "\n",
        "    cudaFree(d_arr);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0f4I_PZti0p",
        "outputId": "211478e0-7bb7-450f-8779-a55a7da2a3d7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing memcpy_demo.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -std=c++11 -Wno-deprecated-gpu-targets memcpy_demo.cu -o memcpy_demo"
      ],
      "metadata": {
        "id": "WvugXrfHtwVN"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./memcpy_demo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMhIIIU_t0Ej",
        "outputId": "8890e3cb-d30f-4cd3-f31a-8d4b49697040"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data copied from Host to Device successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Launch a kernel where GPU threads print values from device memory."
      ],
      "metadata": {
        "id": "nfVnFAk4t96u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile memcpy_demo.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "int main() {\n",
        "\n",
        "    // Host memory (CPU)\n",
        "    int h_arr[5] = {10, 20, 30, 40, 50};\n",
        "\n",
        "    // Device memory pointer (GPU)\n",
        "    int *d_arr;\n",
        "\n",
        "    // Allocate memory on GPU\n",
        "    cudaMalloc((void**)&d_arr, 5 * sizeof(int));\n",
        "\n",
        "    // Copy data from Host to Device\n",
        "    cudaMemcpy(d_arr, h_arr, 5 * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    printf(\"Data copied from Host to Device successfully.\\n\");\n",
        "\n",
        "    cudaFree(d_arr);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmmwtYaVuBK4",
        "outputId": "09188ab9-3a32-4ff8-e12f-e47914d4f827"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting memcpy_demo.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -std=c++11 -Wno-deprecated-gpu-targets memcpy_demo.cu -o memcpy_demo"
      ],
      "metadata": {
        "id": "3omjnpoVuHhG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./memcpy_demo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82B92rTvuXBr",
        "outputId": "58b5d0e2-50af-4cb2-8c46-5e612a79af92"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data copied from Host to Device successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Copy the data back from device to host and print it on CPU."
      ],
      "metadata": {
        "id": "lBoaM-qUubL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile host_device_full.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "/* Device Code (GPU Kernel) */\n",
        "__global__ void modifyArray(int *d_arr) {\n",
        "    int i = threadIdx.x;\n",
        "    d_arr[i] = d_arr[i] + 5;\n",
        "}\n",
        "\n",
        "/* Host Code (CPU) */\n",
        "int main() {\n",
        "\n",
        "    int h_arr[5] = {1, 2, 3, 4, 5};\n",
        "    int *d_arr;\n",
        "\n",
        "    printf(\"Host Array Before GPU:\\n\");\n",
        "    for(int i = 0; i < 5; i++)\n",
        "        printf(\"%d \", h_arr[i]);\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    cudaMalloc((void**)&d_arr, 5 * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_arr, h_arr, 5 * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    modifyArray<<<1,5>>>(d_arr);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Copy Device → Host\n",
        "    cudaMemcpy(h_arr, d_arr, 5 * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Host Array After Copying Back From GPU:\\n\");\n",
        "    for(int i = 0; i < 5; i++)\n",
        "        printf(\"%d \", h_arr[i]);\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    cudaFree(d_arr);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp1o_EoHue5y",
        "outputId": "11458f04-1aca-4a37-fc5c-e4a5126205ff"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing host_device_full.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -std=c++11 -Wno-deprecated-gpu-targets host_device_full.cu -o host_device_full"
      ],
      "metadata": {
        "id": "hcBSlSo4unIZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./host_device_full"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B43xaKO5uqZx",
        "outputId": "2bc6a692-cbaf-4caa-f971-e988cdcf16ec"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Host Array Before GPU:\n",
            "1 2 3 4 5 \n",
            "Host Array After Copying Back From GPU:\n",
            "6 7 8 9 10 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6: Compare CPU times of List/tuple with Numpy arrays."
      ],
      "metadata": {
        "id": "7RV6GcIcuvMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "n = 10_000_000\n",
        "\n",
        "# List\n",
        "lst = list(range(n))\n",
        "start = time.time()\n",
        "lst = [x + 1 for x in lst]\n",
        "end = time.time()\n",
        "print(\"List time:\", end - start)\n",
        "\n",
        "# Tuple\n",
        "tup = tuple(range(n))\n",
        "start = time.time()\n",
        "tup = tuple(x + 1 for x in tup)\n",
        "end = time.time()\n",
        "print(\"Tuple time:\", end - start)\n",
        "\n",
        "# NumPy Array\n",
        "arr = np.arange(n)\n",
        "start = time.time()\n",
        "arr = arr + 1\n",
        "end = time.time()\n",
        "print(\"NumPy time:\", end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P4lwbVJu5JB",
        "outputId": "6cfb2421-64e2-44a1-973c-41fab3f198aa"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List time: 0.5285780429840088\n",
            "Tuple time: 0.9325957298278809\n",
            "NumPy time: 0.025868654251098633\n"
          ]
        }
      ]
    }
  ]
}